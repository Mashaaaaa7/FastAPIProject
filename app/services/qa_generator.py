from transformers import pipeline
import pdfplumber
import re
import unicodedata
from typing import List, Dict
import torch
import random
import requests


class QAGenerator:
    def __init__(self, use_ollama: bool = False):
        self.device = 0 if torch.cuda.is_available() else -1
        self.use_ollama = use_ollama

        if use_ollama:
            print("‚è≥ –ò—Å–ø–æ–ª—å–∑—É–µ–º Ollama –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
            self.ollama_url = "http://localhost:11434/api/generate"
        else:
            print("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é —Ä—É—Å—Å–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")

            self.generator = pipeline(
                "text2text-generation",
                model="cointegrated/rut5-base-multitask",
                device=self.device,
                torch_dtype=torch.float32
            )
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

    def clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        if not text:
            return ""

        text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C' or ch in '\n\t')
        text = re.sub(r'[>~<‚Ä¢¬ª¬´‚Äû"\[\]{}()_\-‚Äì‚Äî]+', '', text)
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    def extract_meaningful_text(self, file_path: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞"""
        chunks = []
        try:
            with pdfplumber.open(file_path) as pdf:
                print(f"üìÑ PDF –∏–º–µ–µ—Ç {len(pdf.pages)} —Å—Ç—Ä–∞–Ω–∏—Ü")

                for i, page in enumerate(pdf.pages):
                    raw_text = page.extract_text()

                    if not raw_text:
                        continue

                    text = self.clean_text(raw_text)

                    if len(text) < 100:
                        continue

                    paragraphs = [p.strip() for p in text.split('\n\n') if len(p.strip()) > 50]

                    for para in paragraphs:
                        sentences = re.split(r'[.!?]+\s+', para)

                        for sent in sentences:
                            sent = self.clean_text(sent)
                            words = sent.split()

                            if (8 <= len(words) <= 50 and
                                    len(sent) > 40 and
                                    sum(1 for c in sent if c.isalpha()) / len(sent) > 0.7):
                                chunks.append({
                                    "text": sent,
                                    "page": i + 1,
                                    "word_count": len(words)
                                })

            print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(chunks)} —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            return chunks

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            return []

    def generate_qa_pair_ollama(self, context: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç QA –ø–∞—Ä—É —á–µ—Ä–µ–∑ Ollama"""
        try:
            prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å–æ–∑–¥–∞–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º:

–¢–µ–∫—Å—Ç: {context[:400]}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Ç–æ—á–Ω–æ):
–í–û–ü–†–û–°: [–≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º]
–û–¢–í–ï–¢: [–æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º]"""

            response = requests.post(
                self.ollama_url,
                json={"model": "llama2", "prompt": prompt, "stream": False}
            )

            if response.status_code != 200:
                return None

            generated = response.json()['response']

            question_match = re.search(r'–í–û–ü–†–û–°:\s*(.*?)(?=\s*–û–¢–í–ï–¢:|$)', generated, re.DOTALL)
            answer_match = re.search(r'–û–¢–í–ï–¢:\s*(.*?)$', generated, re.DOTALL)

            if question_match and answer_match:
                question = self.clean_text(question_match.group(1).strip())
                answer = self.clean_text(answer_match.group(1).strip())

                if len(question) > 15 and len(answer) > 20 and '?' in question:
                    return {
                        "question": question,
                        "answer": answer,
                        "context": context[:200] + "..." if len(context) > 200 else context
                    }
            return None

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Ollama: {e}")
            return None

    def generate_qa_pair_rut5(self, context: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç QA –ø–∞—Ä—É —á–µ—Ä–µ–∑ RuT5"""
        try:
            context_clean = self.clean_text(context[:400])

            if len(context_clean) < 30:
                return None

            prompt = f"–≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç: {context_clean}"

            result = self.generator(
                prompt,
                max_new_tokens=80,
                num_beams=2
            )

            generated = self.clean_text(result[0]['generated_text'])

            parts = generated.split(' | ')
            if len(parts) >= 2:
                question = self.clean_text(parts[0])
                answer = self.clean_text(parts[1])

                if not question.endswith('?'):
                    question += '?'

                if len(question) > 15 and len(answer) > 20:
                    return {
                        "question": question,
                        "answer": answer,
                        "context": context_clean[:200] + "..." if len(context_clean) > 200 else context_clean
                    }
            return None

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ RuT5: {e}")
            return None

    def create_fallback_qa(self, context: str) -> Dict:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é QA –ø–∞—Ä—É"""
        words = context.split()
        key_terms = [word for word in words if len(word) > 4 and word[0].isupper()]

        if key_terms:
            term = random.choice(key_terms[:3]) if key_terms else "–ø–æ–Ω—è—Ç–∏–µ"
            question = f"–ß—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç '{term}' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞?"
            answer = f"{term} –≤ –¥–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –æ–∑–Ω–∞—á–∞–µ—Ç: {context[:180]}..."
        else:
            question = "–ö–∞–∫—É—é –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç?"
            answer = f"–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {context[:200]}..."

        return {
            "question": question,
            "answer": answer,
            "context": context[:150] + "..." if len(context) > 150 else context
        }

    def process_pdf(self, file_path: str, max_cards: int = 10) -> List[Dict]:
        print(f"\nüîÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É {file_path}...")
        print(f"üéØ –¶–µ–ª—å: {max_cards} –∫–∞—Ä—Ç–æ—á–µ–∫")

        chunks = self.extract_meaningful_text(file_path)

        if not chunks:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤!")
            return []

        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(chunks)} —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")

        chunks.sort(key=lambda x: abs(x['word_count'] - 20))

        flashcards = []

        for chunk in chunks[:max_cards * 2]:
            if len(flashcards) >= max_cards:
                break

            if self.use_ollama:
                qa_pair = self.generate_qa_pair_ollama(chunk['text'])
            else:
                qa_pair = self.generate_qa_pair_rut5(chunk['text'])

            if qa_pair:
                flashcard = {
                    "id": len(flashcards) + 1,
                    "question": qa_pair["question"],
                    "answer": qa_pair["answer"],
                    "context": qa_pair["context"],
                    "source": f"Page {chunk['page']}"
                }
                flashcards.append(flashcard)
                print(f"  ‚úÖ [{len(flashcards)}] Q: {qa_pair['question'][:70]}...")
            else:
                fallback_qa = self.create_fallback_qa(chunk['text'])
                flashcard = {
                    "id": len(flashcards) + 1,
                    "question": fallback_qa["question"],
                    "answer": fallback_qa["answer"],
                    "context": fallback_qa["context"],
                    "source": f"Page {chunk['page']}"
                }
                flashcards.append(flashcard)
                print(f"  üîÑ [{len(flashcards)}] Fallback: {fallback_qa['question'][:70]}...")

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(flashcards)} –∫–∞—Ä—Ç–æ—á–µ–∫")
        return flashcards
